# Limitations of Research Grant Craft

> **Please read this document before relying on any output from this tool.**

Research Grant Craft is a **guidance and structuring tool** for researchers
preparing grant proposals. It is not a submission system, not a peer-review
replacement, and not a predictor of funding success.

---

## 1. No guarantee of funding

The reviewer report generated by this tool uses **heuristic signal detection**:
it searches for the presence of specific textual patterns (numbered objectives,
TRL mentions, KPI tables, etc.) and maps match counts to confidence scores.

- **It does not predict the outcome of any evaluation.** Proposals that score
  highly in this tool may still be rejected; proposals that score poorly may
  still be funded.
- **Evaluation panels exercise professional judgement** that no automated
  heuristic can replicate.
- **Call-specific priorities vary.** A strong score on general signals does not
  mean the proposal addresses the specific focus of a given call topic.

Use the reviewer report as a **structured checklist**, not as a score to
optimise for its own sake.

---

## 2. Signal coverage is incomplete

The current signal library covers common structural and content patterns found
in Horizon Europe RIA/IA proposals. It does not cover:

- Domain-specific scientific content quality (e.g., whether the AI methodology
  is technically sound)
- Originality of the research idea
- Credibility of the proposed team
- Budget realism
- Compliance with specific call eligibility rules
- Ethics, gender, or responsible research and innovation (RRI) requirements
- Environmental sustainability commitments

These dimensions require expert human review.

---

## 3. AI-generated draft text must be verified

When LLM-assisted generation is enabled, the draft text produced by the
language model may contain:

- Factual errors or hallucinated references
- Invented statistics or citations
- Text that sounds plausible but is scientifically incorrect
- Content that is not aligned with the actual call topic

**Always verify AI-generated content against primary sources before including
it in a submission.**

---

## 4. Scheme packs are maintained by the community

Scheme packs (evaluation criteria, rubrics, section guidance) are contributed
and maintained by community members. They may:

- Be outdated relative to the current version of a call template
- Contain inaccuracies in criterion weights or thresholds
- Not reflect mid-cycle amendments to a work programme

Always check the official funding body documentation before submitting.

---

## 5. No legal or compliance advice

Nothing in Research Grant Craft constitutes legal advice, financial advice, or
compliance guidance. Questions about eligibility, consortium agreements, IP
ownership, or grant contract terms should be directed to your institutional
research support office or legal counsel.

---

## 6. Accessibility and language limitations

- The tool currently supports **English-language proposals only**. Signal
  patterns are tuned to English text; non-English drafts will score poorly
  regardless of content quality.
- Accessibility features are not yet fully implemented.

---

## Summary

| What the tool does | What the tool does NOT do |
|-------------------|--------------------------|
| Checks structural completeness | Evaluate scientific quality |
| Flags missing standard sections | Guarantee or predict funding |
| Provides a ranked action plan | Replace expert peer review |
| Generates draft text in mock/AI mode | Verify factual accuracy of AI output |
| Supports scheme-specific criteria | Cover all call-specific requirements |
